ğŸ› ï¸ Claude Code ì‘ì—…ì§€ì‹œì„œ - ê¸´ê¸‰ ìˆ˜ì •âœ… Task 1: ê°•í™”ëœ JSON íŒŒì‹± ë¡œì§ (ìµœìš°ì„ )app/services/content_generator.pyì˜ _generate_ai_content ë©”ì„œë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:pythonasync def _generate_ai_content(
    self, 
    slide_type: str, 
    context: Dict[str, Any]
) -> Dict[str, Any]:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¬ë¼ì´ë“œ ì½˜í…ì¸  ìƒì„± (ê°•í™”ëœ JSON íŒŒì‹±)"""
    
    from loguru import logger
    import re
    
    try:
        logger.info(f"ğŸ¤– AI generating content for slide type: {slide_type}")
        
        # McKinsey ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ McKinsey ì»¨ì„¤íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ìŠ¬ë¼ì´ë“œë¥¼ ìœ„í•œ ì „ë¬¸ì ì¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”:
- ìŠ¬ë¼ì´ë“œ ìœ í˜•: {slide_type}
- ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False)}

**ì¤‘ìš”: ë°˜ë“œì‹œ ìˆœìˆ˜í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª… í…ìŠ¤íŠ¸ë‚˜ ë§ˆí¬ë‹¤ìš´ ì—†ì´ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.**

ì‘ë‹µ í˜•ì‹:
{{
    "headline": "McKinsey ìŠ¤íƒ€ì¼ í—¤ë“œë¼ì¸ (So What í¬í•¨, ì •ëŸ‰í™”)",
    "key_points": [
        "í•µì‹¬ í¬ì¸íŠ¸ 1 (ì•¡ì…˜ ì¤‘ì‹¬, ì •ëŸ‰í™”)",
        "í•µì‹¬ í¬ì¸íŠ¸ 2",
        "í•µì‹¬ í¬ì¸íŠ¸ 3"
    ],
    "insights": [
        "Level 4 ì¸ì‚¬ì´íŠ¸ (Action-oriented)"
    ],
    "chart_type": "bar/line/pie/waterfall",
    "data_recommendations": "ë°ì´í„° ì‹œê°í™” ê¶Œì¥ì‚¬í•­"
}}"""

        # OpenAI API í˜¸ì¶œ
        logger.info("ğŸ“¡ Calling OpenAI API...")
        
        response = await self.llm_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "You are a McKinsey consultant. Always respond with pure JSON only, no markdown, no explanations."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1000,
            response_format={"type": "json_object"}  # ğŸ”‘ JSON ëª¨ë“œ ê°•ì œ
        )
        
        raw_content = response.choices[0].message.content
        
        # âœ… ì›ì‹œ ì‘ë‹µ ë¡œê¹… (ê°•ì œ ì¶œë ¥)
        logger.info("=" * 80)
        logger.info("ğŸ“¥ LLM RAW RESPONSE:")
        logger.info(raw_content)
        logger.info("=" * 80)
        
        # âœ… ê°•í™”ëœ JSON ì¶”ì¶œ ë¡œì§
        content = raw_content.strip()
        
        # 1. Markdown ì½”ë“œ ë¸”ë¡ ì œê±°
        if content.startswith("```"):
            # ```json\n{...}\n``` í˜•ì‹
            content = re.sub(r'^```json\s*\n', '', content)
            content = re.sub(r'\n```$', '', content)
            content = re.sub(r'^```\s*\n', '', content)
            logger.info("ğŸ”§ Removed markdown code blocks")
        
        # 2. ì•ë’¤ ì„¤ëª… í…ìŠ¤íŠ¸ ì œê±°
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            content = json_match.group(0)
            logger.info("ğŸ”§ Extracted JSON from text")
        
        # 3. JSON íŒŒì‹± ì‹œë„
        try:
            ai_content = json.loads(content)
            logger.success(f"âœ… AI content parsed successfully")
            return ai_content
            
        except json.JSONDecodeError as json_err:
            logger.error(f"âŒ JSON parsing failed: {json_err}")
            logger.error(f"ğŸ“„ Cleaned content: {content[:200]}...")
            raise
            
    except Exception as e:
        logger.error(f"âŒ AI generation failed: {type(e).__name__}: {str(e)}")
        logger.warning("âš ï¸ Falling back to mock content")
        
        # Mock í´ë°±
        return self._generate_mock_content(slide_type, context)ğŸ”‘ í•µì‹¬ ê°œì„ ì‚¬í•­:
response_format={"type": "json_object"} ì¶”ê°€

OpenAI GPT-4ì˜ JSON ëª¨ë“œ ê°•ì œ í™œì„±í™”
ì´ ì˜µì…˜ì€ LLMì´ ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤



ê°•í™”ëœ ì •ê·œì‹ íŒŒì‹±

Markdown ì½”ë“œ ë¸”ë¡ ìë™ ì œê±°
ì„¤ëª… í…ìŠ¤íŠ¸ì—ì„œ JSONë§Œ ì¶”ì¶œ



ë‹¤ë‹¨ê³„ ë¡œê¹…

ì›ì‹œ ì‘ë‹µ ì „ì²´ ì¶œë ¥
ì •ì œ ê³¼ì • ê° ë‹¨ê³„ ë¡œê¹…


âœ… Task 2: Loguru ì„¤ì • ê°•í™”app/core/config.py ë˜ëŠ” main.pyì— ë‹¤ìŒ ì¶”ê°€:pythonfrom loguru import logger
import sys

# Loguru ì„¤ì • ê°•í™”
logger.remove()  # ê¸°ë³¸ í•¸ë“¤ëŸ¬ ì œê±°
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level="INFO",
    colorize=True,
    backtrace=True,
    diagnose=True
)

logger.add(
    "logs/app.log",
    rotation="500 MB",
    retention="10 days",
    level="DEBUG",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function} - {message}"
)

logger.info("âœ… Loguru configured successfully")âœ… Task 3: í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ê°œì„ send_request.pyë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:pythonimport requests
import json
import time

# ê¸´ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ (Pydantic ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼ìš©)
test_document = """
ì•„ì‹œì•„ ì‹œì¥ ì§„ì¶œ ì „ëµ ë¶„ì„

1. ì‹œì¥ ê°œìš”
- ì•„ì‹œì•„ ì‹œì¥ ê·œëª¨: 5ì¡°ì›
- ì—°í‰ê·  ì„±ì¥ë¥ : 15%
- ì£¼ìš” êµ­ê°€: ë² íŠ¸ë‚¨, ì¸ë„ë„¤ì‹œì•„, íƒœêµ­

2. ê¸°íšŒ ìš”ì¸
- ì¤‘ì‚°ì¸µ ê¸‰ì¦: 5ë…„ ë‚´ 2ë°° ì„±ì¥ ì˜ˆìƒ
- ë””ì§€í„¸ ì „í™˜ ê°€ì†í™”
- ì •ë¶€ ì§€ì› ì •ì±… ê°•í™”

3. ì§„ì¶œ ì „ëµ
- 1ë‹¨ê³„: ë² íŠ¸ë‚¨ ì‹œì¥ ì„ ì  (í–¥í›„ 6ê°œì›”)
- 2ë‹¨ê³„: ì¸ë„ë„¤ì‹œì•„ í™•ì¥ (12ê°œì›” í›„)
- 3ë‹¨ê³„: ì§€ì—­ í—ˆë¸Œ êµ¬ì¶• (18ê°œì›” í›„)

4. ì˜ˆìƒ íš¨ê³¼
- ë§¤ì¶œ 30% ì¦ê°€
- ì‹œì¥ ì ìœ ìœ¨ 15% ë‹¬ì„±
- ROI 150% ë‹¬ì„±
"""

payload = {
    "document": test_document,
    "style": "mckinsey",
    "target_audience": "executive",
    "num_slides": 5,
    "language": "ko"
}

print("ğŸ“¡ Sending request to API...")
print(f"ğŸ“„ Document length: {len(test_document)} chars")

try:
    response = requests.post(
        "http://localhost:8000/api/v1/generate-ppt",
        json=payload,
        timeout=60
    )
    
    print(f"âœ… Response status: {response.status_code}")
    print(f"ğŸ“¥ Response body: {json.dumps(response.json(), indent=2, ensure_ascii=False)}")
    
    if response.status_code == 200:
        result = response.json()
        ppt_id = result.get("ppt_id")
        print(f"\nğŸ¯ PPT ID: {ppt_id}")
        print("\nâ³ Waiting for generation to complete...")
        
        # ìƒíƒœ í™•ì¸ (ìµœëŒ€ 60ì´ˆ)
        for i in range(60):
            time.sleep(1)
            status_response = requests.get(f"http://localhost:8000/api/v1/ppt-status/{ppt_id}")
            status = status_response.json()
            
            print(f"[{i+1}s] Status: {status.get('status')} | Progress: {status.get('progress', 0)}%")
            
            if status.get('status') == 'completed':
                print("\nâœ… PPT generation completed!")
                print(f"ğŸ“Š Quality Score: {status.get('quality_score')}")
                print(f"ğŸ“¥ Download URL: {status.get('download_url')}")
                break
            elif status.get('status') == 'failed':
                print(f"\nâŒ Generation failed: {status.get('error')}")
                break
                
except Exception as e:
    print(f"âŒ Error: {type(e).__name__}: {str(e)}")âœ… Task 4: Docker ë¡œê·¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ë³„ë„ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰:powershell# ë°©ë²• 1: ì „ì²´ ë¡œê·¸ ì‹¤ì‹œê°„ ë³´ê¸°
docker-compose logs -f app

# ë°©ë²• 2: íŠ¹ì • í‚¤ì›Œë“œë§Œ í•„í„°ë§
docker-compose logs -f app | Select-String -Pattern "AI|LLM|RAW|JSON|ContentGenerator"

# ë°©ë²• 3: íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ìƒì„¸ ë¡œê·¸
docker-compose logs -f --timestamps appğŸ¯ ì‹¤í–‰ ìˆœì„œ1ë‹¨ê³„: ì½”ë“œ ìˆ˜ì • ì ìš©
powershell# ContentGenerator ìˆ˜ì • (ìœ„ Task 1 ì½”ë“œ)
code app/services/content_generator.py

# Loguru ì„¤ì • ì¶”ê°€ (ìœ„ Task 2 ì½”ë“œ)
code app/core/config.py2ë‹¨ê³„: Docker ì¬ë¹Œë“œ
powershelldocker-compose down
docker-compose build --no-cache app
docker-compose up -d3ë‹¨ê³„: ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘
powershell# ìƒˆ PowerShell ì°½ì—ì„œ
docker-compose logs -f app | Select-String -Pattern "AI|RAW|JSON"4ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ìš”ì²­ ì „ì†¡
powershell# ì›ë˜ PowerShell ì°½ì—ì„œ
python send_request.pyğŸ“Š ì˜ˆìƒ ê²°ê³¼âœ… ì„±ê³µ ì‹œ ë¡œê·¸:
2025-10-16 15:30:45 | INFO     | ContentGenerator:_generate_ai_content - ğŸ¤– AI generating content for slide type: executive_summary
2025-10-16 15:30:45 | INFO     | ContentGenerator:_generate_ai_content - ğŸ“¡ Calling OpenAI API...
2025-10-16 15:30:47 | INFO     | ContentGenerator:_generate_ai_content - ================================================================================
2025-10-16 15:30:47 | INFO     | ContentGenerator:_generate_ai_content - ğŸ“¥ LLM RAW RESPONSE:
2025-10-16 15:30:47 | INFO     | ContentGenerator:_generate_ai_content - {"headline": "ì•„ì‹œì•„ ì‹œì¥ì´ 3ë…„ ë‚´ 50% ì„±ì¥í•˜ì—¬ ìµœëŒ€ ê¸°íšŒ ì œê³µ", "key_points": [...], ...}
2025-10-16 15:30:47 | INFO     | ContentGenerator:_generate_ai_content - ================================================================================
2025-10-16 15:30:47 | SUCCESS  | ContentGenerator:_generate_ai_content - âœ… AI content parsed successfullyâŒ ì‹¤íŒ¨ ì‹œ ë¡œê·¸:
2025-10-16 15:30:47 | ERROR    | ContentGenerator:_generate_ai_content - âŒ JSON parsing failed: Expecting value: line 1 column 1
2025-10-16 15:30:47 | ERROR    | ContentGenerator:_generate_ai_content - ğŸ“„ Cleaned content: Here is the JSON: {...
2025-10-16 15:30:47 | WARNING  | ContentGenerator:_generate_ai_content - âš ï¸ Falling back to mock content